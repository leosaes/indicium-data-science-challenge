{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2de75481",
   "metadata": {},
   "source": [
    "# 1 Feature Engineering\n",
    "\n",
    "\n",
    "\n",
    "Para fazer a limpeza decidi criar uma função chamada clean_data() para ser utilizado tanto com o dataframe de treino quanto com os dados do desafio após. \n",
    "\n",
    "Iniciei com a coluna \"Certificate\", uniformizando o formato das strings e denominando \"Unknown\" os valores NaN.\n",
    "\n",
    "Para a coluna \"Released_Year\" fiz a mudança de \"PG\" para \"1995\", possível erro do dataset descoberto durante análise dos dados, e então a transformação de string para inteiro.\n",
    "\n",
    "Na coluna \"Gross\" removi as strings de vírgula e transformei os dados em float caso não nulos.\n",
    "\n",
    "Em \"Runtime\" removi o que não era número da string e mudei o tipo de dado para float.\n",
    "\n",
    "Agora já partindo para colunas categóricas, devido a grande extensão de diretores evidenciei os 50 de maior frequência no dataframe e o restante denominei \"Other_Directors\".\n",
    "\n",
    "Com as 4 colunas de \"Star1\" a \"Star4\", juntei os atores em uma única coluna \"Star\" em forma de lista, cada filme contendo uma lista dos atores. Então decidi permanecer no dataframe apenas os 100 mais comuns e o restante se tornou \"Other_Stars\". Com estes dados utilizei o MultiLabelBinarizer, transformando cada ator em uma coluna com uma matriz de dados binários, 0 e 1, para caso estejam presentes nos filmes ou não.\n",
    "\n",
    "Em seguida fiz o mesmo processo com a coluna \"Genre\", transformando os dados em uma lista, pegando os 15 mais comuns e tornando o resto em \"Other_Genres\", passando também pelo processo do MultiLabelBinarizer. No fim juntei tanto as novas colunas MLB de atores quanto de gêneros ao dataframe e removi as colunas \"Star1\" a \"Star4\", \"Stars\", \"Genre\" e \"Series_Title\".\n",
    "\n",
    "Por último, padronizei as strings da coluna \"Overview\" para se apresentarem em letra minúscula.\n",
    "\n",
    "Aqui também já preparei a função fix_dataframe(), para igualar as colunas do dataframe do desafio com as colunas preparadas aqui na etapa de Featurne Engineering, como as colunas criadas com o MultiLabelBinarizer, e preenchendo com 0 caso esses dados não estejam presentes no novo dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5056b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "192e44a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "\n",
    "  df['Certificate'] = df['Certificate'].apply(lambda x: str(x).strip().upper() if pd.notna(x) else 'Unknown')\n",
    "\n",
    "\n",
    "  df.loc[df['Released_Year'] == 'PG', 'Released_Year'] = 1995\n",
    "  \n",
    "  df['Released_Year'] = df['Released_Year'].apply(lambda x: int(str(x)) if pd.notna(x) else np.nan)\n",
    "\n",
    "\n",
    "  df['Gross'] = df['Gross'].apply(lambda x: float(str(x).replace(',','')) if pd.notna(x) else np.nan)\n",
    "\n",
    "\n",
    "  df['Runtime'] = df['Runtime'].str.extract(r'(\\d+)').astype(float)\n",
    "\n",
    "\n",
    "  top_directors = df['Director'].value_counts().head(50).index.tolist()\n",
    "\n",
    "  df['Director'] = df['Director'].apply(lambda x: x if x in top_directors else 'Other_Directors')\n",
    "\n",
    "\n",
    "  df['Stars'] = df[[\"Star1\", \"Star2\", \"Star3\", \"Star4\"]].values.tolist()\n",
    "\n",
    "  all_stars = pd.Series([s for stars in df['Stars'] for s in stars]).value_counts().head(100).index.tolist()\n",
    "  \n",
    "  df['Stars'] = df['Stars'].apply(lambda x: [s if s in all_stars else 'Other_Stars' for s in x])\n",
    "\n",
    "  mlb_star = MultiLabelBinarizer()\n",
    "\n",
    "  stars = pd.DataFrame(mlb_star.fit_transform(df['Stars']), columns=mlb_star.classes_,index=df.index)\n",
    "\n",
    "  \n",
    "  df['Genre'] = df['Genre'].str.split(', ')\n",
    "\n",
    "  all_genres = pd.Series([g for genres in df['Genre'] for g in genres]).value_counts().head(15).index.tolist()\n",
    "  \n",
    "  df['Genre'] = df['Genre'].apply(lambda x: [g if g in all_genres else 'Other_Genres' for g in x])\n",
    "\n",
    "  mlb_genre = MultiLabelBinarizer()\n",
    "\n",
    "  genres = pd.DataFrame(mlb_genre.fit_transform(df['Genre']), columns=mlb_genre.classes_,index=df.index)\n",
    "\n",
    " \n",
    "  df = pd.concat([df,genres,stars],axis=1)\n",
    "\n",
    "\n",
    "  df[\"Overview\"] = df[\"Overview\"].str.lower()\n",
    "\n",
    "  df.drop(columns=[\"Genre\",\"Star1\", \"Star2\", \"Star3\", \"Star4\"],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "  df.drop(columns=[\"Series_Title\",\"Stars\"],axis=1,inplace=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "\n",
    "def fix_dataframe(new_df, expected_columns, fill_value=0):\n",
    "  \n",
    "  for col in expected_columns:\n",
    "    if col not in new_df.columns:\n",
    "      new_df[col] = fill_value\n",
    "  \n",
    "  new_df = new_df[expected_columns]\n",
    "\n",
    "  return new_df  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de2124",
   "metadata": {},
   "source": [
    "# 2 Modelo\n",
    "\n",
    "Como o modelo de machine learning é responsável de prever a nota do IMDB, uma variável contínua, estamos falando de um problema de regressão. \n",
    "\n",
    "Para atingir esse objetivo, separei os dados em:\n",
    "- Features Numéricas: 'Released_Year','Runtime','Meta_score','No_of_Votes','Gross'\n",
    "- Features Categóricas: 'Certificate','Director'\n",
    "- Features de texto: 'Overview'\n",
    "- Features Multi-Label Binarizer: Matrizes binárias transformadas previamente em colunas de gêneros e atores\n",
    "O restante dos dados do dataframe, o objetivo da predição 'IMDB_Rating', não foi utilizado aqui.\n",
    "\n",
    "Na fase de transformações, criei uma pipeline para cada seção de features:\n",
    "- Features Numéricas: SimpleImputer() com mediana para preencher valores faltantes e o StandardScaler() para normalização das diferentes escalas numéricas\n",
    "- Features Categóricas: SimpleImputer() com o valor mais comum, mesmo já assegurando que não haveriam mais dados nulos aqui, e OneHotEncoder() para converter as categorias em variáveis binárias e lidar com valores desconhecidos.\n",
    "- Features de texto: TfidVectorizer() para capturar a importância das palavras de acordo com o contexto, limitando a dimensionalidade para 500 para evitar overfitting e removendo palavras irrelevantes em inglês, como preposições e artigos \n",
    "- Features Multi-Label Binarizer: O termo \"passthrough\" pois os dados já estão transformados\n",
    "Com os steps designados, finalizei a transformação com ColumnTransformer().\n",
    "\n",
    "Por fim, para completar a pipeline da machine learning com um modelo de regressão, escolhi o Random Forest Regressor, propício para prever valores numérics contínuos. Entre seus prós estão que o algorítmo captura relações complexas entre variáveis, lida bem com outliers, reduz overfitting através de suas múltiplas árvores e é versátil com os diferentes tipos de dados. Já seus contras se destacam a consumação de memória caso tenha muitas árvores e que não foge muito dos valores da faixa limitada no treino.\n",
    "As alternativas seriam Linear Regression (o dataset é muito complexo), XGBoost (Random Forest se apresenta suficiente e mais adequado pelo tamanho do dataset, tempo de otimização, recursos e performance) e Redes Neurais (o dataset é muito pequeno).\n",
    "\n",
    "Enfim, fiz a separação dos dados em 70% para treinamento e 30% para teste e apliquei a pipeline nos dados.\n",
    "\n",
    "As métricas utilizadas para medir a performance foram o Mean Absolute Error (MAE), Mean Squarred Error (MSE), Root Mean Squared Error (RMSE) e Coeficiente de Determinação (R²), ideais para modelos de regressão. O MAE é uma medida mais interpretável, o MSE e o RMSE penalizam mais os erros maiores (como outliers) e o R² explica quanto da variabilidade dos dados o modelo consegue explicar.\n",
    "\n",
    "Como resultado da performance do modelo:\n",
    "- MAE: 0.16, apresentando uma boa precisão\n",
    "- MSE: 0.04, indicando poucos erros grandes \n",
    "- RMSE: 0.20, mostrando que os erros se concentram em torno de 0.2 das notas do IMDB \n",
    "- R²: 0.50, significando que o modelo captura metade da variabilidade\n",
    "\n",
    "Um exemplo de predição com os dados de treino e teste é o filme The Best Years of Our Lives, que com a nota 8.0 teve a previsão de nota 8.0 (7.989, arredondado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e2200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo dado de teste 1: 453    8.0\n",
      "Name: IMDB_Rating, dtype: float64\n",
      "Exemplo de predição 1: [7.989]\n",
      "Erro absoluto médio: 0.16\n",
      "Erro quadrático médio: 0.04\n",
      "Raiz do erro quadrático médio: 0.20\n",
      "Coeficiente de determinação: 0.50\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('desafio_indicium_imdb.csv').drop('Unnamed: 0',axis=1)\n",
    "\n",
    "df = clean_data(df)\n",
    "\n",
    "\n",
    "numeric_features = ['Released_Year','Runtime','Meta_score','No_of_Votes','Gross']\n",
    "categorical_features = ['Certificate','Director']\n",
    "text_features = 'Overview'\n",
    "mlb_features = [c for c in df.columns if c not in numeric_features + categorical_features + [text_features,'IMDB_Rating']]\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "                      (\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "                      (\"scaler\",StandardScaler())\n",
    "                      ])\n",
    "\n",
    "categorial_transformer = Pipeline(steps=[\n",
    "                        (\"imputer\",SimpleImputer(strategy=\"most_frequent\")),\n",
    "                        (\"encoder\",OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "                        ])\n",
    "\n",
    "text_transformer = Pipeline(steps=[\n",
    "                  (\"vectorizer\",TfidfVectorizer(max_features=500,stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "mlb_transformer = \"passthrough\"\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "              transformers=[\n",
    "                (\"num\",numeric_transformer,numeric_features),\n",
    "                (\"cat\",categorial_transformer,categorical_features),\n",
    "                (\"txt\",text_transformer,text_features),\n",
    "                (\"mlb\",mlb_transformer,mlb_features)\n",
    "              ],\n",
    "              remainder=\"drop\"\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "          (\"preprocessor\",preprocessor),\n",
    "          (\"regressor\",RandomForestRegressor(n_estimators=200,random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "X = df.drop(columns=[\"IMDB_Rating\"])\n",
    "y = df['IMDB_Rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "\n",
    "print(f\"Exemplo dado de teste 1: {y_test[:1]}\")\n",
    "print(f\"Exemplo de predição 1: {y_pred[:1]}\")\n",
    "print(f\"Erro absoluto médio: {mae:.2f}\")\n",
    "print(f\"Erro quadrático médio: {mse:.2f}\")\n",
    "print(f\"Raiz do erro quadrático médio: {rmse:.2f}\")\n",
    "print(f\"Coeficiente de determinação: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3adf34",
   "metadata": {},
   "source": [
    "# 3 Salvar o modelo\n",
    "\n",
    "Utilizar Pickle para salvar a pipeline e as colunas que devem estar presentes no dataframe para serem utilizadas com novos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "721f1c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "final_model = {\n",
    "  'pipeline': pipeline,\n",
    "  'expected_columns': X_train.columns.tolist(),\n",
    "}\n",
    "\n",
    "with open('model_indicium.pkl','wb') as f:\n",
    "  pickle.dump(final_model,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae768a0",
   "metadata": {},
   "source": [
    "# 4 Utilizar modelo pré-treinado\n",
    "\n",
    "Importei as funções de limpeza de dados e conformização do dataframe para que possa ser utilizado com o modelo\n",
    "\n",
    "Importei também o modelo pré-treinado e as \"expected_columns\"\n",
    "\n",
    "Então transformei os novos dados em um dataframe e o utilizei as funções para que então pudesse fazer a predição da nota do IMDB, tendo como resultado a nota 8.7865."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "02eb60bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nota do IMDB: [8.7865]\n"
     ]
    }
   ],
   "source": [
    "import data_cleaner\n",
    "\n",
    "with open('model_indicium.pkl','rb') as f:\n",
    "  model = pickle.load(f)\n",
    "\n",
    "test_movie = pd.DataFrame([{'Series_Title': 'The Shawshank Redemption', \n",
    "                            'Released_Year': '1994', \n",
    "                            'Certificate': 'A', \n",
    "                            'Runtime': '142 min', \n",
    "                            'Genre': 'Drama', \n",
    "                            'Overview': 'Two imprisoned men bond over a number of years, finding solace and eventual redemption through acts of common decency.', \n",
    "                            'Meta_score': 80.0, \n",
    "                            'Director': 'Frank Darabont', \n",
    "                            'Star1': 'Tim Robbins', \n",
    "                            'Star2': 'Morgan Freeman', \n",
    "                            'Star3': 'Bob Gunton', \n",
    "                            'Star4': 'William Sadler', \n",
    "                            'No_of_Votes': 2343110, \n",
    "                            'Gross': '28,341,469'\n",
    "}])\n",
    "\n",
    "\n",
    "df_test = data_cleaner.clean_data(test_movie)\n",
    "\n",
    "movie = data_cleaner.fix_dataframe(df_test,model['expected_columns'])\n",
    "\n",
    "IMDB_Rate = model['pipeline'].predict(movie)\n",
    "\n",
    "print(f\"Nota do IMDB: {IMDB_Rate}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
